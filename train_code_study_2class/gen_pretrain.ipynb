{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_script.faster_rcnn_detector import LitFasterRCNN\n",
    "from pl_script.unet_smp import LitUnetSmp\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Add path of NIH pretrained checkpoint file here\n",
    "target_ckpt_paths = [\n",
    "    [\"tu-tf_efficientnetv2_m\", \"/home/lorenzo/kaggle_model/train_code_study_2class/pl_output/unet_smp_nih-640-aug-epoch=04-gkf0-val_loss=0.0852.ckpt\"],\n",
    "]\n",
    "for (backbone_name, target_ckpt_path) in target_ckpt_paths:\n",
    "    config_dict = OmegaConf.merge(OmegaConf.load(\"config.yaml\"), OmegaConf.load(\"model/unet_smp_nih.yaml\"))\n",
    "    config_dict.unet_smp.backbone_name = backbone_name\n",
    "    config_dict.unet_smp.num_classes = 15\n",
    "    \n",
    "    output_path = \"./pretrained\"\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    model = LitUnetSmp.load_from_checkpoint(target_ckpt_path, config=config_dict)\n",
    "\n",
    "    study_level_classifier = model.model.seg.encoder\n",
    "\n",
    "    torch.save(study_level_classifier.state_dict(), os.path.join(output_path, target_ckpt_path.split(\"/\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_script.faster_rcnn_detector import LitFasterRCNN\n",
    "from pl_script.unet_smp import LitUnetSmp\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Add path of NIH pretrained checkpoint file here\n",
    "target_ckpt_paths = [\n",
    "    [\"tf_efficientnetv2_m\", \"/home/lorenzo/kaggle_model/train_code_study_2class/pl_output/unet_smp_nih-640-aug-epoch=14-gkf0-val_loss=0.0840.ckpt\"],\n",
    "]\n",
    "for (backbone_name, target_ckpt_path) in target_ckpt_paths:\n",
    "    config_dict = OmegaConf.merge(OmegaConf.load(\"config.yaml\"), OmegaConf.load(\"model/unet_smp_nih.yaml\"))\n",
    "    config_dict.unet_smp.backbone_name = backbone_name\n",
    "    config_dict.unet_smp.num_classes = 15\n",
    "    \n",
    "    output_path = \"./pretrained\"\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    model = LitUnetSmp.load_from_checkpoint(target_ckpt_path, config=config_dict)\n",
    "\n",
    "    study_level_classifier = model.model.seg.encoder\n",
    "\n",
    "    torch.save(study_level_classifier.state_dict(), os.path.join(output_path, target_ckpt_path.split(\"/\")[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('siim-covid': conda)",
   "name": "python3711jvsc74a57bd01f4f94af67ce9786ed44436abf6e58989dd7431b8e6c2b499cb33e77cf9b50df"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "metadata": {
   "interpreter": {
    "hash": "55da4bfabaa72f6d23e190de73e880f50e1e61f38162ba3c994fd2cd39574748"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}