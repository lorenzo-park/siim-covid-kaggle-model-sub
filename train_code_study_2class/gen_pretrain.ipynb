{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_script.faster_rcnn_detector import LitFasterRCNN\n",
    "from pl_script.unet_smp import LitUnetSmp\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Add path of NIH pretrained checkpoint file here\n",
    "target_ckpt_paths = [\n",
    "    [\"tf_efficientnetv2_m\", \"/home/lorenzo/kaggle_model/train_code_study_2class/pl_output/unet_smp_nih-640-aug-epoch=14-gkf0-val_loss=0.0840.ckpt\"],\n",
    "]\n",
    "for (backbone_name, target_ckpt_path) in target_ckpt_paths:\n",
    "    config_dict = OmegaConf.merge(OmegaConf.load(\"config.yaml\"), OmegaConf.load(\"model/unet_smp_nih.yaml\"))\n",
    "    config_dict.unet_smp.backbone_name = backbone_name\n",
    "    config_dict.unet_smp.num_classes = 15\n",
    "    \n",
    "    output_path = \"./pretrained\"\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    model = LitUnetSmp.load_from_checkpoint(target_ckpt_path, config=config_dict)\n",
    "\n",
    "    study_level_classifier = model.model.seg.encoder\n",
    "\n",
    "    torch.save(study_level_classifier.state_dict(), os.path.join(output_path, target_ckpt_path.split(\"/\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_script.faster_rcnn_detector import LitFasterRCNN\n",
    "from pl_script.unet_smp import LitUnetSmp\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/siim-covid/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pl_script.unet_smp_2c import LitUnetSmp2C\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "target_ckpt_paths = [\n",
    "    \"/shared/lorenzo/pl_output/unet_smp_2c-640-aug-epoch=04-sgkf0-val_loss=0.3958.ckpt\",\n",
    "    \"/shared/lorenzo/pl_output/unet_smp_2c-640-aug-epoch=01-sgkf1-val_loss=0.3897.ckpt\",\n",
    "    \"/shared/lorenzo/pl_output/unet_smp_2c-640-aug-epoch=01-sgkf2-val_loss=0.4096.ckpt\",\n",
    "    \"/shared/lorenzo/pl_output/unet_smp_2c-640-aug-epoch=00-sgkf3-val_loss=0.3919.ckpt\",\n",
    "    \"/shared/lorenzo/pl_output/unet_smp_2c-640-aug-epoch=00-sgkf4-val_loss=0.3826.ckpt\",\n",
    "]\n",
    "for target_ckpt_path in target_ckpt_paths:\n",
    "    # backbone_name = target_ckpt_path.split(\"/\")[-1].split(\"-\")[0].replace(\"_\",\"-\")\n",
    "    config_dict = OmegaConf.merge(OmegaConf.load(\"config.yaml\"), OmegaConf.load(\"model/unet_smp_2c.yaml\"))\n",
    "    config_dict.smp_path = None\n",
    "    config_dict.model = \"unet_smp_2c\"\n",
    "    \n",
    "    output_path = \"./output/study-unet-smp-2c/\"\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    model = LitUnetSmp2C.load_from_checkpoint(target_ckpt_path, config=config_dict)\n",
    "\n",
    "    study_level_classifier = model.model\n",
    "\n",
    "    torch.save(study_level_classifier.state_dict(), os.path.join(output_path, target_ckpt_path.split(\"/\")[-1]))\n",
    "    # torch.save(detector.state_dict(), os.path.join(output_path, \"detector.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2740593139.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_119748/2740593139.py\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    \"/shared/lorenzo/pl_output/tu_tf_efficientnetv2_l-384-aug-epoch=03-sgkf4-val_loss=0.7819.ckpt,\u001b[0m\n\u001b[0m                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "from pl_script.faster_rcnn_detector import LitFasterRCNN\n",
    "from pl_script.timm import LitTimm\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "target_ckpt_paths = [\n",
    "    \"/home/lorenzo/siim-covid/pl_output/timm_nih-384-aug-epoch=09-gkf0-val_loss=0.1708.ckpt\",\n",
    "]\n",
    "for target_ckpt_path in target_ckpt_paths:\n",
    "    # backbone_name = target_ckpt_path.split(\"/\")[-1].split(\"-\")[0].replace(\"_\",\"-\")\n",
    "    backbone_name = \"swin_large_patch4_window12_384_in22k\"\n",
    "    config_dict = OmegaConf.merge(OmegaConf.load(\"config.yaml\"), OmegaConf.load(\"model/timm.yaml\"))\n",
    "    config_dict.model_config.num_classes = 15\n",
    "    \n",
    "    output_path = \"./pretrained\"\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    model = LitTimm.load_from_checkpoint(target_ckpt_path, config=config_dict)\n",
    "\n",
    "    study_level_classifier = model.model.base\n",
    "\n",
    "    torch.save(study_level_classifier.state_dict(), os.path.join(output_path, target_ckpt_path.split(\"/\")[-1]))\n",
    "    # torch.save(detector.state_dict(), os.path.join(output_path, \"detector.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('siim-covid': conda)",
   "name": "python3711jvsc74a57bd01f4f94af67ce9786ed44436abf6e58989dd7431b8e6c2b499cb33e77cf9b50df"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "55da4bfabaa72f6d23e190de73e880f50e1e61f38162ba3c994fd2cd39574748"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}